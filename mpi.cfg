# Some Linux distributions have RPM's for some MPI implementations.
# In such a case, headers and libraries usually are in default system
# locations, and you should not need any special configuration.

# If you do not have MPI distribution in a default location, please
# uncomment and fill-in appropriately the following lines. Yo can use
# as examples the [mpich2], [openmpi],  and [deinompi] sections
# below the [mpi] section (wich is the one used by default).

# If you specify multiple locations for includes and libraries,
# please separate them with the path separator for your platform,
# i.e., ':' on Unix-like systems and ';' on Windows


# Daint configuration
# ---------------------
[mpi]
mpi_dir              = /opt/cray/pe/mpt/7.7.15/gni/mpich-gnu/8.2
cuda_dir             = /opt/nvidia/cudatoolkit10.2/10.2.89_3.28-7.0.2.1_2.17__g52c0314

mpicc                = /opt/cray/pe/craype/2.7.0/bin/cc
mpicxx               = /opt/gcc/8.3.0/bin/c++

## define_macros        =
## undef_macros         =
include_dirs         = %(mpi_dir)s/include %(cuda_dir)s/include
libraries            = mpich mpl rt pthread cuda cudart
library_dirs         = %(mpi_dir)s/lib %(cuda_dir)s/lib64
runtime_library_dirs = %(mpi_dir)s/lib %(cuda_dir)s/lib64
